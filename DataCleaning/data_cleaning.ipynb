{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Essentials: Data Cleaning\n",
    "    Benj McMullin\n",
    "    Math 403\n",
    "    10/31/2023\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "The g\\_t\\_results.csv file is a set of parent-reported scores on their child's Gifted and Talented tests. \n",
    "The two tests, OLSAT and NNAT, are used by NYC to determine if children are qualified for gifted programs.\n",
    "The OLSAT Verbal has 16 questions for Kindergardeners and 30 questions for first, second, and third graders.\n",
    "The NNAT has 48 questions. Each test assigns 1 point to each question asked (so there are no non integer scores).\n",
    "Using this dataset, answer the following questions.\n",
    "\n",
    "\n",
    "\n",
    "1) What column has the highest number of null values and what percent of its values are null? Print the answer as a tuple with (column name, percentage). Make sure the second value is a percent.\n",
    "\n",
    "2) List the columns that should be numeric that aren't. Print the answer as a tuple.\n",
    "\n",
    "3) How many third graders have scores outside the valid range for the OLSAT Verbal Score? Print the answer\n",
    "\n",
    "4) How many data values are missing (NaN)? Print the number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Column with the highest number of null values: ('School Assigned', 76.06837606837607)\n",
      "\n",
      "Part Two\n",
      "2. Columns that should be numeric but aren't: ('OLSAT Verbal Score', 'OLSAT Verbal Percentile', 'NNAT Non Verbal Raw Score')\n",
      "3. Third graders with scores outside the valid range for OLSAT Verbal Score: 1\n",
      "4. Number of missing data values (NaN): 193\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('g_t_results.csv')\n",
    "\n",
    "# 1. What column has the highest number of null values and what percent of its values are null?\n",
    "null_counts = df.isnull().sum()\n",
    "max_null_column = null_counts.idxmax()\n",
    "percentage_null = (null_counts[max_null_column] / len(df)) * 100\n",
    "answer_1 = (max_null_column, percentage_null)\n",
    "print(\"1. Column with the highest number of null values:\", answer_1)\n",
    "\n",
    "# 2. List the columns that should be numeric but aren't.\n",
    "output = (\"OLSAT Verbal Score\", \"OLSAT Verbal Percentile\", \"NNAT Non Verbal Raw Score\")\n",
    "print(\"\\nPart Two\")\n",
    "print(\"2. Columns that should be numeric but aren't:\", output)\n",
    "\n",
    "# 3. How many third graders have scores outside the valid range for the OLSAT Verbal Score?\n",
    "third_graders = df[df['Entering Grade Level'] == '3']\n",
    "valid_range_olsat_verbal = ('0', '30')\n",
    "invalid_olsat_verbal_scores = third_graders[\n",
    "    ~third_graders['OLSAT Verbal Score'].between(valid_range_olsat_verbal[0], valid_range_olsat_verbal[1])\n",
    "]\n",
    "answer_3 = len(invalid_olsat_verbal_scores)\n",
    "print(\"3. Third graders with scores outside the valid range for OLSAT Verbal Score:\", answer_3)\n",
    "\n",
    "# 4. How many data values are missing (NaN)?\n",
    "missing_data_count = df.isna().sum().sum()\n",
    "print(\"4. Number of missing data values (NaN):\", missing_data_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "imdb.csv contains a small set of information about 99 movies. Clean the data set by doing the following in order: \n",
    "\n",
    "1) Remove duplicate rows by dropping the first **or** last. Print the shape of the dataframe after removing the rows.\n",
    "\n",
    "2) Drop all rows that contain missing data. Print the shape of the dataframe after removing the rows.\n",
    "\n",
    "3) Remove rows that have data outside valid data ranges and explain briefly how you determined your ranges for each column.\n",
    "\n",
    "4) Identify and drop columns with three or fewer different values. Print a tuple with the names of the columns dropped.\n",
    "\n",
    "5) Convert the titles to all lower case.\n",
    "\n",
    "Print the first five rows of your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after removing duplicate rows: (93, 13)\n",
      "Shape after removing rows with missing data: (64, 13)\n",
      "Shape after removing rows with data outside valid ranges: (60, 13)\n",
      "Columns dropped: ('color', 'language')\n",
      "       director_name  duration        gross  \\\n",
      "0    Martin Scorsese       240  116866727.0   \n",
      "1        Shane Black       195  408992272.0   \n",
      "2  Quentin Tarantino       187   54116191.0   \n",
      "3   Kenneth Lonergan       186      46495.0   \n",
      "4      Peter Jackson       186  258355354.0   \n",
      "\n",
      "                                 genres                          movie_title  \\\n",
      "0          Biography|Comedy|Crime|Drama              the wolf of wall street   \n",
      "1               Action|Adventure|Sci-Fi                           iron man 3   \n",
      "2  Crime|Drama|Mystery|Thriller|Western                    the hateful eight   \n",
      "3                                 Drama                             margaret   \n",
      "4                     Adventure|Fantasy  the hobbit: the desolation of smaug   \n",
      "\n",
      "   title_year country       budget  imdb_score  \\\n",
      "0        2013     USA  100000000.0         8.2   \n",
      "1        2013     USA  200000000.0         7.2   \n",
      "2        2015     USA   44000000.0         7.9   \n",
      "3        2011     usa   14000000.0         6.5   \n",
      "4        2013     USA  225000000.0         7.9   \n",
      "\n",
      "                                              actors  movie_facebook_likes  \n",
      "0  Leonardo DiCaprio,Matthew McConaughey,Jon Favreau                138000  \n",
      "1          Robert Downey Jr.,Jon Favreau,Don Cheadle                 95000  \n",
      "2          Craig Stark,Jennifer Jason Leigh,ZoÃ« Bell                114000  \n",
      "3        Matt Damon,Kieran Culkin,John Gallagher Jr.                     0  \n",
      "4              Aidan Turner,Adam Brown,James Nesbitt                 83000  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('imdb.csv')\n",
    "\n",
    "# 1. Remove duplicate rows by dropping the first or last\n",
    "df = df.drop_duplicates(keep='first')\n",
    "print(\"Shape after removing duplicate rows:\", df.shape)\n",
    "\n",
    "# 2. Drop all rows that contain missing data\n",
    "df = df.dropna()\n",
    "print(\"Shape after removing rows with missing data:\", df.shape)\n",
    "\n",
    "# 3. Remove rows that have data outside of valid data ranges\n",
    "# Assume valid data ranges as follows (you can adjust these as needed):\n",
    "valid_duration = (30, None)  # At least 30 minutes long\n",
    "valid_imdb_score = (0, None)  # Positive imdb_score\n",
    "valid_title_year = (2000, None)  # Title year after 2000\n",
    "df = df[\n",
    "    (df['duration'] >= valid_duration[0]) &\n",
    "    (df['imdb_score'] >= valid_imdb_score[0]) &\n",
    "    (df['title_year'] >= valid_title_year[0])\n",
    "]\n",
    "print(\"Shape after removing rows with data outside valid ranges:\", df.shape)\n",
    "\n",
    "# 4. Identify and drop columns with three or fewer different values\n",
    "columns_to_drop = [col for col in df.columns if df[col].nunique() <= 3]\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "print(\"Columns dropped:\", tuple(columns_to_drop))\n",
    "\n",
    "# 5. Convert the titles to all lower case\n",
    "df['movie_title'] = df['movie_title'].str.lower()\n",
    "\n",
    "# Print the first five rows of the cleaned dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "Load housing.csv into a dataframe with index=0. Descriptions of the features are in housing_data_description.txt for your convenience.  \n",
    "The goal is to construct a regression model that predicts SalePrice using the other features of the dataset.  Do this as follows:\n",
    "\n",
    "\t1) Identify and handle the missing data.  Hint: Dropping every row with some missing data is not a good choice because it gives you an empty dataframe.  What can you do instead?\n",
    "    \n",
    "    2) Add two new features: \n",
    "\t\ta) Remodeled: Whether or not a house has been remodeled with a Y if it has been\n",
    "\t\t   remodeled, or a N if it has not.\n",
    "\t\t\n",
    "\t\tb) TotalPorch: Using the 5 different porch/deck columns, create a new column that\n",
    "\t\t   provides the total square footage of all the decks and porches for each house.\n",
    "    \n",
    "\t3) Identify the variable with nonnumeric values that are misencoded as numbers.  One-hot encode it. Hint: don't forget to remove one of the encoded columns to prevent collinearity with the constant column (which you will add later).\n",
    "    \n",
    "    4) Add a constant column to the dataframe.\n",
    "\n",
    "    5) Save a copy of the dataframe.\n",
    "\n",
    "\t6) Choose four categorical featrues that seem very important in predicting SalePrice. One-hot encode these features and remove all other categorical features.\n",
    "\t\t\n",
    "\t7) Run an OLS using all numerical data regression on your model.  \n",
    "\n",
    "\t\n",
    "Print the ten features that have the highest coef in your model. Then print the summary. Don't print the OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_3168\\1434290423.py:40: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(df_html, header=0, index_col=0)[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Neighborhood_StoneBr</th>\n",
       "      <td>48520.0000</td>\n",
       "      <td>32700.000</td>\n",
       "      <td>1.482</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-15700.000</td>\n",
       "      <td>113000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighborhood_NridgHt</th>\n",
       "      <td>39470.0000</td>\n",
       "      <td>32400.000</td>\n",
       "      <td>1.219</td>\n",
       "      <td>0.223</td>\n",
       "      <td>-24100.000</td>\n",
       "      <td>103000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighborhood_NoRidge</th>\n",
       "      <td>34950.0000</td>\n",
       "      <td>32400.000</td>\n",
       "      <td>1.080</td>\n",
       "      <td>0.280</td>\n",
       "      <td>-28500.000</td>\n",
       "      <td>98400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>15280.0000</td>\n",
       "      <td>2933.129</td>\n",
       "      <td>5.211</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9529.110</td>\n",
       "      <td>21000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>13820.0000</td>\n",
       "      <td>1272.377</td>\n",
       "      <td>10.865</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11300.000</td>\n",
       "      <td>16300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass_20</th>\n",
       "      <td>10120.0000</td>\n",
       "      <td>49700.000</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.839</td>\n",
       "      <td>-87400.000</td>\n",
       "      <td>108000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighborhood_Veenker</th>\n",
       "      <td>9546.0889</td>\n",
       "      <td>32500.000</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.769</td>\n",
       "      <td>-54200.000</td>\n",
       "      <td>73300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <td>8308.0905</td>\n",
       "      <td>2552.346</td>\n",
       "      <td>3.255</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3300.755</td>\n",
       "      <td>13300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass_30</th>\n",
       "      <td>8090.8279</td>\n",
       "      <td>49600.000</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.870</td>\n",
       "      <td>-89200.000</td>\n",
       "      <td>105000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass_40</th>\n",
       "      <td>7831.3905</td>\n",
       "      <td>52100.000</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.881</td>\n",
       "      <td>-94400.000</td>\n",
       "      <td>110000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            coef    std err       t  P>|t|     [0.025  \\\n",
       "Neighborhood_StoneBr  48520.0000  32700.000   1.482  0.139 -15700.000   \n",
       "Neighborhood_NridgHt  39470.0000  32400.000   1.219  0.223 -24100.000   \n",
       "Neighborhood_NoRidge  34950.0000  32400.000   1.080  0.280 -28500.000   \n",
       "GarageCars            15280.0000   2933.129   5.211  0.000   9529.110   \n",
       "OverallQual           13820.0000   1272.377  10.865  0.000  11300.000   \n",
       "MSSubClass_20         10120.0000  49700.000   0.204  0.839 -87400.000   \n",
       "Neighborhood_Veenker   9546.0889  32500.000   0.294  0.769 -54200.000   \n",
       "BsmtFullBath           8308.0905   2552.346   3.255  0.001   3300.755   \n",
       "MSSubClass_30          8090.8279  49600.000   0.163  0.870 -89200.000   \n",
       "MSSubClass_40          7831.3905  52100.000   0.150  0.881 -94400.000   \n",
       "\n",
       "                        0.975]  \n",
       "Neighborhood_StoneBr  113000.0  \n",
       "Neighborhood_NridgHt  103000.0  \n",
       "Neighborhood_NoRidge   98400.0  \n",
       "GarageCars             21000.0  \n",
       "OverallQual            16300.0  \n",
       "MSSubClass_20         108000.0  \n",
       "Neighborhood_Veenker   73300.0  \n",
       "BsmtFullBath           13300.0  \n",
       "MSSubClass_30         105000.0  \n",
       "MSSubClass_40         110000.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "house = pd.read_csv('housing.csv')\n",
    "\n",
    "# 1. Drop all columns with more than 100 missing values\n",
    "nan = house.isnull().sum()\n",
    "drop = nan[nan > 100].index\n",
    "house.drop(columns=drop, inplace=True)\n",
    "\n",
    "# 2. Drop all rows with any missing values\n",
    "house.dropna(inplace=True)\n",
    "\n",
    "# 3. Drop all columns with only one unique value\n",
    "house['Remodeled'] = 'N'\n",
    "house.loc[house['YearRemodAdd'] > house['YearBuilt'], 'Remodeled'] = 'Y'\n",
    "\n",
    "house['TotalPorch'] = house['WoodDeckSF'] + house['OpenPorchSF'] + house['EnclosedPorch'] + house['3SsnPorch'] + house['ScreenPorch']\n",
    "\n",
    "# 4. Create a new column called 'Remodeled' that is 'Y' if YearRemodAdd is greater than YearBuilt and 'N' otherwise\n",
    "house = pd.get_dummies(house, columns=['MSSubClass'], dtype='int64')\n",
    "\n",
    "# 5. Create a new column called 'TotalPorch' that is the sum of WoodDeckSF, OpenPorchSF, EnclosedPorch, 3SsnPorch, and ScreenPorch\n",
    "housing_cpy = house.copy()\n",
    "\n",
    "# 6. Create dummy variables for the following columns: MSSubClass\n",
    "house = pd.get_dummies(house, columns=['SaleCondition', 'ExterCond', 'BldgType', 'Neighborhood'], dtype='int64')\n",
    "\n",
    "# 7. Create dummy variables for the following columns: SaleCondition, ExterCond, BldgType, and Neighborhood\n",
    "house = house.select_dtypes(exclude=['object'])\n",
    "\n",
    "# 8. Create a new column called 'SalePrice' that is the log of the SalePrice column\n",
    "house.drop(columns=['SalePrice'], inplace=True)\n",
    "house = sm.add_constant(house)\n",
    "house['SalePrice'] = housing_cpy['SalePrice']\n",
    "house.dropna(inplace=True)\n",
    "model = sm.OLS(house['SalePrice'], house.drop(columns=['SalePrice']))\n",
    "\n",
    "# 9. Create a new column called 'SalePrice' that is the log of the SalePrice column\n",
    "results = model.fit()\n",
    "df_html = results.summary().tables[1].as_html()\n",
    "df = pd.read_html(df_html, header=0, index_col=0)[0]\n",
    "\n",
    "# 10. Print the top 10 most significant variables sorted by their coefficient\n",
    "df.sort_values(by='coef', ascending=False, inplace=True)\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "\n",
    "Using the copy of the dataframe you created in Problem 3, one-hot encode all the categorical variables.\n",
    "Print the shape of the dataframe and run OLS.\n",
    "\n",
    "Print the ten features that have the highest coef in your model and the summary.\n",
    "Write a couple of sentences discussing which model is better and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_3168\\962585096.py:9: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(df_html, header=0, index_col=0)[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RoofMatl_Membran</th>\n",
       "      <td>148200.0</td>\n",
       "      <td>32300.00</td>\n",
       "      <td>4.593</td>\n",
       "      <td>0.000</td>\n",
       "      <td>84900.000</td>\n",
       "      <td>211000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofMatl_Metal</th>\n",
       "      <td>125200.0</td>\n",
       "      <td>31100.00</td>\n",
       "      <td>4.031</td>\n",
       "      <td>0.000</td>\n",
       "      <td>64300.000</td>\n",
       "      <td>186000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofMatl_WdShngl</th>\n",
       "      <td>96950.0</td>\n",
       "      <td>21100.00</td>\n",
       "      <td>4.593</td>\n",
       "      <td>0.000</td>\n",
       "      <td>55500.000</td>\n",
       "      <td>138000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual_Ex</th>\n",
       "      <td>83370.0</td>\n",
       "      <td>36600.00</td>\n",
       "      <td>2.279</td>\n",
       "      <td>0.023</td>\n",
       "      <td>11600.000</td>\n",
       "      <td>155000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition2_PosA</th>\n",
       "      <td>79230.0</td>\n",
       "      <td>38800.00</td>\n",
       "      <td>2.040</td>\n",
       "      <td>0.042</td>\n",
       "      <td>3013.848</td>\n",
       "      <td>155000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofStyle_Shed</th>\n",
       "      <td>63630.0</td>\n",
       "      <td>35900.00</td>\n",
       "      <td>1.770</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-6890.275</td>\n",
       "      <td>134000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofMatl_Tar&amp;Grv</th>\n",
       "      <td>55340.0</td>\n",
       "      <td>22100.00</td>\n",
       "      <td>2.499</td>\n",
       "      <td>0.013</td>\n",
       "      <td>11900.000</td>\n",
       "      <td>98800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofMatl_Roll</th>\n",
       "      <td>50500.0</td>\n",
       "      <td>30200.00</td>\n",
       "      <td>1.670</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-8848.812</td>\n",
       "      <td>110000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofMatl_CompShg</th>\n",
       "      <td>44100.0</td>\n",
       "      <td>19100.00</td>\n",
       "      <td>2.313</td>\n",
       "      <td>0.021</td>\n",
       "      <td>6693.554</td>\n",
       "      <td>81500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighborhood_StoneBr</th>\n",
       "      <td>37930.0</td>\n",
       "      <td>7924.35</td>\n",
       "      <td>4.786</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22400.000</td>\n",
       "      <td>53500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          coef   std err      t  P>|t|     [0.025    0.975]\n",
       "RoofMatl_Membran      148200.0  32300.00  4.593  0.000  84900.000  211000.0\n",
       "RoofMatl_Metal        125200.0  31100.00  4.031  0.000  64300.000  186000.0\n",
       "RoofMatl_WdShngl       96950.0  21100.00  4.593  0.000  55500.000  138000.0\n",
       "GarageQual_Ex          83370.0  36600.00  2.279  0.023  11600.000  155000.0\n",
       "Condition2_PosA        79230.0  38800.00  2.040  0.042   3013.848  155000.0\n",
       "RoofStyle_Shed         63630.0  35900.00  1.770  0.077  -6890.275  134000.0\n",
       "RoofMatl_Tar&Grv       55340.0  22100.00  2.499  0.013  11900.000   98800.0\n",
       "RoofMatl_Roll          50500.0  30200.00  1.670  0.095  -8848.812  110000.0\n",
       "RoofMatl_CompShg       44100.0  19100.00  2.313  0.021   6693.554   81500.0\n",
       "Neighborhood_StoneBr   37930.0   7924.35  4.786  0.000  22400.000   53500.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "encode_columns = housing_cpy.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
    "housing_cpy = pd.get_dummies(housing_cpy, columns=encode_columns, dtype='int64')\n",
    "\n",
    "# Step 1: Remove columns with excessive missing values\n",
    "results = sm.OLS(housing_cpy['SalePrice'], housing_cpy.drop(columns=['SalePrice'])).fit()\n",
    "\n",
    "df_html = results.summary().tables[1].as_html()\n",
    "df = pd.read_html(df_html, header=0, index_col=0)[0]\n",
    "\n",
    "# Step 2: Sort the features by their coefficients\n",
    "df.sort_values(['coef'], ascending=False, inplace=True)\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
