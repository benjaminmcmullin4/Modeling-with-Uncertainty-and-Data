{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volume 3: Discrete Hidden Markov Models\n",
    "    Benj McMullin\n",
    "    Math 405\n",
    "    2/13/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import string\n",
    "import codecs\n",
    "from hmmlearn import hmm as hmmlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems 1-5\n",
    "This is the HMM class that you will be adding functions to throughout the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM(object):\n",
    "    \"\"\"\n",
    "    Finite state space hidden Markov model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Problem 1\n",
    "    def __init__(self, A, B, pi):\n",
    "        \"\"\"\n",
    "        Initialize an HMM with parameters A, B, and pi.\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.pi = pi\n",
    "    \n",
    "    def init_matrix(self, z):\n",
    "        # Initialize alpha\n",
    "        T = z.shape[0]\n",
    "        return np.empty((T, self.A.shape[0])), T\n",
    "    \n",
    "    # Problem 2\n",
    "    def forward_pass(self, z):\n",
    "        \"\"\"\n",
    "        Compute the forward probability matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : ndarray of shape (T,)\n",
    "            The observation sequence\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        alpha : ndarray of shape (T, n)\n",
    "            The forward probability matrix\n",
    "        \"\"\"\n",
    "        # Initialize alpha\n",
    "        alpha,T = self.init_matrix(z)\n",
    "\n",
    "        # Set the first row of alpha\n",
    "        alpha[0] = self.pi * self.B[z[0]]\n",
    "\n",
    "        # Iterate through the rest of alpha\n",
    "        for t in range(1, T):\n",
    "            alpha[t] = self.B[z[t],:] * np.sum(alpha[t-1,:] * self.A, axis=1)\n",
    "\n",
    "        return alpha\n",
    "    \n",
    "    # Problem 4\n",
    "    def backward_pass(self, z):\n",
    "        \"\"\"\n",
    "        Compute the backward probability matrix and gamma values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : ndarray of shape (T,)\n",
    "            The observation sequence\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        beta : ndarray of shape (T, n)\n",
    "            The backward probability matrix\n",
    "        gamma : ndarray of shape (T, n)\n",
    "            The state probability matrix\n",
    "        \"\"\"\n",
    "        # Initialize beta\n",
    "        beta,T = self.init_matrix(z)\n",
    "        beta[-1] = np.ones(self.A.shape[0])\n",
    "\n",
    "        # Calcualte beta_t's\n",
    "        for t in range(T-2, -1, -1):\n",
    "            beta[t] = (self.B[z[t+1],:] * beta[t+1,:]) @ self.A\n",
    "\n",
    "        # Calculate gamma using forward pass\n",
    "        gamma = self.forward_pass(z)*beta\n",
    "        gamma = gamma / np.sum(gamma, axis=1).reshape(-1,1)\n",
    "\n",
    "        return beta, gamma\n",
    "    \n",
    "    # Problem 5\n",
    "    def viterbi_algorithm(self, z):\n",
    "        \"\"\"\n",
    "        Compute the most likely hidden state sequence using the Viterbi algorithm.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : ndarray of shape (T,)\n",
    "            The observation sequence\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x*: ndarray of shape (T,)\n",
    "            The most likely state sequence\n",
    "        \"\"\"\n",
    "        # Initialize eta and x*\n",
    "        eta,T = self.init_matrix(z)\n",
    "        x_str = np.empty(T, dtype=int)\n",
    "        eta[0] = self.pi * self.B[z[0]]\n",
    "\n",
    "        # Iterate through the rest of eta\n",
    "        for t in range(1, T):\n",
    "            eta[t] = self.B[z[t],:] * np.max(eta[t-1,:]*self.A, axis=1)\n",
    "\n",
    "        # Calculate x* from eta\n",
    "        x_str[-1] = np.argmax(eta[-1])\n",
    "        for t in range(T-2, -1, -1):\n",
    "            x_str[t] = np.argmax(eta[t]*self.A[:,x_str[t+1]])\n",
    "        \n",
    "        return x_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 test case\n",
    "\n",
    "Use the following HMM and code to test your HMM class.\n",
    "Compare the output to `forward_pass` with the lab pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009629599999999997\n"
     ]
    }
   ],
   "source": [
    "pi = np.array([.6, .4])\n",
    "A = np.array([[.7, .4],[.3, .6]])\n",
    "B = np.array([[.1,.7],[.4, .2],[.5, .1]])\n",
    "z_example = np.array([0, 1, 0, 2])\n",
    "example_hmm = HMM(A, B, pi)\n",
    "\n",
    "alpha=example_hmm.forward_pass(z_example)\n",
    "print(np.sum(alpha[-1,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "\n",
    "Consider the following (very simplified) model of the price of a stock over time as an HMM.\n",
    "The observation states will be the change in the value of the stock.\n",
    "For simplicity, we will group these into five values: large decrease, small decrease, no change, small increase, large increase, labeled as integers from 0 to 4.\n",
    "The hidden state will be the overall trends of the market.\n",
    "We'll consider the market to have three possible states: declining in value (bear market), not changing in value (stagnant), and increasing in value (bull market), labeled as integers from 0 to 2.\n",
    "Let the HMM modeling this scenario have parameters\n",
    "$$\n",
    "\\boldsymbol\\pi=\\begin{bmatrix}\n",
    "1/3 \\\\ 1/3 \\\\ 1/3\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "A=\\begin{bmatrix}\n",
    "0.5 & 0.3 & 0 \\\\\n",
    "0.5 & 0.3 & 0.3 \\\\\n",
    "0 & 0.4 & 0.7\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "B=\\begin{bmatrix}\n",
    "0.3 & 0.1 & 0 \\\\\n",
    "0.3 & 0.2 & 0.1 \\\\\n",
    "0.3 & 0.4 & 0.3 \\\\\n",
    "0.1 & 0.2 & 0.4 \\\\\n",
    "0 & 0.1 & 0.2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "The file `stocks.npy` contains a sequence of 50 observations drawn from this HMM.\n",
    "What is the probability of this observation sequence given these model parameters?\n",
    "Use your implementation of the forward pass algorithm from Problem 2 to find the answer.\n",
    "Note that the answer is very small, because there are lots of possible observation sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMM parameter setup\n",
    "pi = np.array([1/3, 1/3, 1/3])\n",
    "A = np.array([\n",
    "    [0.5, 0.3, 0.0],\n",
    "    [0.5, 0.3, 0.3],\n",
    "    [0.0, 0.4, 0.7]\n",
    "])\n",
    "B = np.array([\n",
    "    [0.3, 0.1, 0.0],\n",
    "    [0.3, 0.2, 0.1],\n",
    "    [0.3, 0.4, 0.3],\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.0, 0.1, 0.2]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability: 6.671115114537777e-34\n"
     ]
    }
   ],
   "source": [
    "# Load stocks data\n",
    "data = np.load('stocks.npy')\n",
    "\n",
    "# Define HMM\n",
    "hmm = HMM(A, B, pi)\n",
    "\n",
    "# Run the forward pass\n",
    "alpha = hmm.forward_pass(data)\n",
    "print(f\"Probability: {np.sum(alpha[-1, :])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "\n",
    "Create a method `backward_pass` in your HMM class to implement the backward pass algorithm.\n",
    "This function should accept the observation sequence $\\mathbf{z}$ and return two arrays of the $\\beta_t(i)$ and $\\gamma_t(i)$ values.\n",
    "\n",
    "Test your function on the example HMM, and compare the output with the lab pdf.\n",
    "\n",
    "With your function and the stock model from Problem 3, answer the following question: given the observation sequence in `stocks.npy`, what is the most likely initial hidden state $X_0$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0302  0.02792]\n",
      " [0.0812  0.1244 ]\n",
      " [0.38    0.26   ]\n",
      " [1.      1.     ]]\n",
      "[[0.18816981 0.81183019]\n",
      " [0.51943175 0.48056825]\n",
      " [0.22887763 0.77112237]\n",
      " [0.8039794  0.1960206 ]]\n"
     ]
    }
   ],
   "source": [
    "# Test case; compare your output with what is in the lab pdf\n",
    "beta, gamma = example_hmm.backward_pass(z_example)\n",
    "print(beta)\n",
    "print(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most likely initial state: 0\n"
     ]
    }
   ],
   "source": [
    "# Load stocks data\n",
    "data = np.load('stocks.npy')\n",
    "\n",
    "# Define HMM\n",
    "hmm = HMM(A, B, pi)\n",
    "\n",
    "# Run the backward pass\n",
    "beta, gamma = hmm.backward_pass(data)\n",
    "print(\"Most likely initial state:\", np.argmax(beta[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5\n",
    "Creating a method `viterbi_algorithm` in your HMM class to implement the Viterbi algorithm.\n",
    "This function should accept the observation sequence $\\mathbf{z}$ and return the most likely state sequence $\\mathbf{x}^*$.\n",
    "\n",
    "Test your function on the example HMM and compare output with the lab pdf.\n",
    "\n",
    "Apply your function to the stock market HMM from Problem 3.\n",
    "With the observaition sequence from `stocks.npy`, what is the most likely sequence of hidden states?\n",
    "Is the initial state of the most likely sequence the same as the most likely initial state you found in Problem 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Test case\n",
    "xstar = example_hmm.viterbi_algorithm(z_example)\n",
    "print(xstar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 1 0 0 1 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 0 0 0 1 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 2 2 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Run viterbi\n",
    "xstar = hmm.viterbi_algorithm(data)\n",
    "print(xstar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your observations here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6\n",
    "\n",
    "Train a `hmmlearn.hmm.CategoricalHMM` on `declaration.txt`. Use `N=2` states and `M=len(set(obs))=27` observation values (26 lower case characters and 1 whitespace character).\n",
    "Use `n_iter=200` and `tol=1e-4`.\n",
    "\n",
    "Once the learning algorithm converges, analyze the state observation matrix $B$. Note which rows correspond to the largest and smallest probability values in each column of $B$, and check the corresponding characters. The HMM should have detected a vowel state and a consonant state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_translate(a, my_dict):\n",
    "    # translate numpy array from symbols to state numbers or vice versa\n",
    "    return np.vectorize(my_dict.__getitem__)(a)\n",
    "\n",
    "def prep_data(filename):\n",
    "    \"\"\"\n",
    "    Reads in the file and prepares it for use in an HMM.\n",
    "    Returns:\n",
    "        symbols (dict): a dictionary that maps characters to their integer values\n",
    "        obs_sequence (ndarray): an array of integers representing the read-in text\n",
    "    \"\"\"\n",
    "    # Get the data as a single string\n",
    "    with codecs.open(filename, encoding='utf-8') as f:\n",
    "        data=f.read().lower()  # and convert to all lower case\n",
    "    # remove punctuation and newlines\n",
    "    remove_punct_map = {ord(char): \n",
    "                        None for char in string.punctuation+\"\\n\\r\"}\n",
    "    data = data.translate(remove_punct_map)\n",
    "    # make a list of the symbols in the data\n",
    "    symbols = sorted(list(set(data)))\n",
    "    # convert the data to a NumPy array of symbols\n",
    "    a = np.array(list(data))\n",
    "    # make a conversion dictionary from symbols to state numbers\n",
    "    symbols_to_obsstates = {x:i for i,x in enumerate(symbols)}\n",
    "    # convert the symbols in a to state numbers\n",
    "    obs_sequence = vec_translate(a,symbols_to_obsstates)\n",
    "    return symbols, obs_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first state represents vowels and the second state represents consonants\n",
      " , 0.2713, 0.0687\n",
      "a, 0.1344, 0.0000\n",
      "b, 0.0000, 0.0352\n",
      "c, 0.0000, 0.0502\n",
      "d, 0.0009, 0.0188\n",
      "e, 0.2393, 0.0000\n",
      "f, 0.0000, 0.0549\n",
      "g, 0.0009, 0.0110\n",
      "h, 0.0059, 0.0000\n",
      "i, 0.1266, 0.0000\n",
      "j, 0.0000, 0.0000\n",
      "k, 0.0009, 0.0000\n",
      "l, 0.0000, 0.0392\n",
      "m, 0.0012, 0.0339\n",
      "n, 0.0000, 0.1872\n",
      "o, 0.1374, 0.0000\n",
      "p, 0.0006, 0.0371\n",
      "q, 0.0000, 0.0000\n",
      "r, 0.0000, 0.1158\n",
      "s, 0.0144, 0.1147\n",
      "t, 0.0000, 0.1753\n",
      "u, 0.0589, 0.0000\n",
      "v, 0.0000, 0.0180\n",
      "w, 0.0000, 0.0349\n",
      "x, 0.0000, 0.0035\n",
      "y, 0.0074, 0.0000\n",
      "z, 0.0000, 0.0016\n"
     ]
    }
   ],
   "source": [
    "symbols, obs = prep_data('declaration.txt')\n",
    "\n",
    "# Define HMM\n",
    "hmm = hmmlearn.CategoricalHMM(n_components=3, n_iter=200, tol=1e-4)\n",
    "hmm.fit(obs.reshape(-1, 1), lengths=[obs.shape[0]])\n",
    "\n",
    "# Print out the HMM parameters\n",
    "B = hmm.emissionprob_.T\n",
    "print('The first state represents vowels and the second state represents consonants')\n",
    "for i in range(len(B)):\n",
    "    print(u\"{}, {:0.4f}, {:0.4f}\".format(symbols[i], *B[i,:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7\n",
    "\n",
    "Repeat the same calculation with `WarAndPeace.txt` with 2 hidden states. Interpret/explain your results. Which Cyrillic characters appear to be vowels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " , 0.4188, 0.0342\n",
      "а, 0.0000, 0.1958\n",
      "б, 0.0122, 0.0000\n",
      "в, 0.0494, 0.0000\n",
      "г, 0.0174, 0.0000\n",
      "д, 0.0262, 0.0000\n",
      "е, 0.0361, 0.1556\n",
      "ж, 0.0061, 0.0000\n",
      "з, 0.0205, 0.0000\n",
      "и, 0.0000, 0.1490\n",
      "й, 0.0271, 0.0000\n",
      "к, 0.0348, 0.0000\n",
      "л, 0.0376, 0.0000\n",
      "м, 0.0275, 0.0000\n",
      "н, 0.0401, 0.0000\n",
      "о, 0.0000, 0.2678\n",
      "п, 0.0244, 0.0000\n",
      "р, 0.0165, 0.0000\n",
      "с, 0.0929, 0.0000\n",
      "т, 0.0355, 0.0000\n",
      "у, 0.0007, 0.0651\n",
      "ф, 0.0017, 0.0000\n",
      "х, 0.0086, 0.0000\n",
      "ц, 0.0009, 0.0000\n",
      "ч, 0.0164, 0.0000\n",
      "ш, 0.0047, 0.0000\n",
      "щ, 0.0003, 0.0000\n",
      "ъ, 0.0000, 0.0000\n",
      "ы, 0.0000, 0.0418\n",
      "ь, 0.0000, 0.0497\n",
      "э, 0.0079, 0.0000\n",
      "ю, 0.0136, 0.0034\n",
      "я, 0.0223, 0.0374\n",
      "ё, 0.0000, 0.0001\n"
     ]
    }
   ],
   "source": [
    "symbols, obs = prep_data('WarAndPeace.txt')\n",
    "\n",
    "# Define HMM\n",
    "hmm = hmmlearn.CategoricalHMM(n_components=3, n_iter=200, tol=1e-4)\n",
    "hmm.fit(obs.reshape(-1, 1), lengths=[obs.shape[0]])\n",
    "\n",
    "# Print out the HMM parameters\n",
    "B = hmm.emissionprob_.T\n",
    "for i in range(len(B)):\n",
    "    print(u\"{}, {:0.4f}, {:0.4f}\".format(symbols[i], *B[i,:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vowels are а, е, и, о, с, у, ы, ь, ю, я"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
